% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/abc-workflow.R
\name{abc_adaptive}
\alias{abc_adaptive}
\title{Perform ABC sequential adaptive fitting}
\usage{
abc_adaptive(
  obsdata,
  priors_list,
  sim_fn,
  scorer_fn,
  n_sims,
  acceptance_rate,
  ...,
  max_time = 5 * 60,
  converged_fn = default_termination_fn(),
  obsscores = NULL,
  distance_method = "euclidean",
  seed = NULL,
  knots = NULL,
  parallel = FALSE,
  max_recover = 3,
  allow_continue = interactive(),
  debug_errors = FALSE,
  kernel = "epanechnikov",
  bw = 0.1,
  scoreweights = NULL
)
}
\arguments{
\item{obsdata}{The observational data. The data in this will typically
be a named list, but could be anything, e.g. dataframe. It is the reference
data that the simulation model is aiming to replicate.}

\item{priors_list}{a named list of priors specified as a \code{abc_prior} S3 object
(see \code{priors()}), this can include derived values as unnamed 2-sided
formulae, where the LHS of the formula will be assigned to the value of the
RHS, plus optionally a set of constraints as one sided formulae where the
RHS of the formulae will resolve to a boolean value.}

\item{sim_fn}{a user defined function that takes a set of parameters named
the same as \code{priors_list}. It must return a simulated data set in the
same format as \code{obsdata}, or that can be compared to \code{simdata} by
\code{scorer_fn}. This function must not refer to global parameters, and will be
automatically crated with \code{carrier}.}

\item{scorer_fn}{a user supplied function that matches the following
signature \code{scorer_fn(simdata, obsdata, ....)}, i.e. it takes data in the
format of \code{simdata} paired with the original \code{obsdata} and returns a named
list of component scores per simulation. This function can make use of the
\verb{calculate_*()} set of functions to compare components of the simulation to
the original data. This function must not refer to global parameters, and
will be automatically crated with \code{carrier}. If this is a purrr style
function then \code{.x} will refer to simulation output and \code{.y} to original
observation data.}

\item{n_sims}{The number of simulations to run per wave (for SMC and Adaptive)
or overall (for Rejection). For rejection sampling a large number is
recommended, for the others sma}

\item{acceptance_rate}{What proportion of simulations to keep in ABC rejection
or hard ABC parts of the algorithms.}

\item{...}{must be empty}

\item{max_time}{the maximum time in seconds to spend in ABC waves before admitting
defeat. This time may not be all used if the algorithm converges.}

\item{converged_fn}{a function that takes a \code{summary} and \code{per_param} input
and generates a logical indicator that the function has converged}

\item{obsscores}{Summary scores for the observational data. This will
be a named list, and is equivalent to the output of \code{scorer_fn},
on the observed data. If not given typically it will be assumed to be all
zeros.}

\item{distance_method}{what metric is used to combine \code{simscores} and \code{obsscores}
and is one of \code{"euclidean"}, \code{"manhattan"}, or \code{"mahalanobis"}.}

\item{seed}{an optional random seed}

\item{knots}{the number of knots to model the CDF with. Optional, and will be
typically inferred from the data size. Small numbers tend to work better if
we expect the distribution to be unimodal.}

\item{parallel}{parallelise the simulation? If this is set to true then the
simulation step will be parallelised using \code{furrr}. For this to make any
difference it must have been set up with the following:
\code{future::plan(future::multisession, workers = parallel::detectCores()-2)}}

\item{max_recover}{if the effective sample size of SMC or adaptive algorithms
drops below 200, the algorithm will retry the wave with double the sample
size to try and recover the shape of the distribution, up to a maximum of
\code{max_recover} times.}

\item{allow_continue}{if SMC or adaptive algorithms have not converged after
\code{max_time} allow the algorithm to interactively prompt the user to continue.}

\item{debug_errors}{Errors that crop up in \code{sim_fn} during a simulation due
to anomolous value combinations are hard to debug. If this flag is set,
whenever a \code{sim_fn} or \code{scorer_fn} throws an error an interactive debugging
session is started with the failing parameter combinations. This is not
compatible with running in parallel.}

\item{kernel}{one of \code{"epanechnikov"}, \code{"uniform"}, \code{"triangular"}, \code{"biweight"},
or \code{"gaussian"}. The kernel defines how the distance metric translates into
the importance weight that decides whether a given simulation and associated
parameters should be rejected or held for the next round.}

\item{bw}{for Adaptive ABC data distributions are smoothed before modelling
the CDF. Over smoothing can reduce convergence, under-smoothing may result
in noisy posterior estimates. This is in units of the ESS and defaults to
0.1.}

\item{scoreweights}{A named vector with names matching output of \code{scorer_fn}
that defines the importance of this component of the scoring in the overall
distance and weighting of any given simulation. This can be used to assign
more weight on certain parts of the model output.}
}
\value{
an S3 object of class \code{abc_fit} this contains the following:
\itemize{
\item type: the type of ABC algorithm
\item iterations: number of completed iterations
\item converged: boolean - did the result meet convergence criteria
\item waves: a list of dataframes of wave convergence metrics
\item summary: a dataframe with the summary of the parameter fits after each wave.
\item priors: the priors for the fit as a \code{abc_prior} S3 object
\item posteriors: the final wave posteriors
}
}
\description{
This function will execute a simulation for a random selection of parameters.
Based on the \code{acceptance_rate} it will reject a proportion of the results.
The remaining results are weighted (using a kernel with a tolerance
equivalent to half the acceptance rate). Empirical distributions are fitted
to weighted parameter particles and from these proposals are generated for
further waves by fresh sampling. Waves are executed until a maximum is
reached or the results converge sufficiently that the changes between waves
are small. A relatively small number of simulations may be attempted with a
high acceptance rate, over multiple waves.
}
\examples{

fit = abc_adaptive(
  obsdata = example_obsdata(),
  priors_list = example_priors_list(),
  sim_fn = example_sim_fn,
  scorer_fn = example_scorer_fn,
  n_sims = 1000,
  acceptance_rate = 0.25,
  max_time = 5, # 5 seconds to fit within examples limit
  parallel = FALSE,
  allow_continue = FALSE
)

summary(fit)

}
\concept{workflow}
